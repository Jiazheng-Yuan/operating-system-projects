
<!-- saved from url=(0048)https://grader2.eecs.umich.edu/eecs482/project2/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Project 2 -- thread library</title>
<style>@media print {#ghostery-purple-box {display:none !important}}</style></head>
<body>
<h1>Project 2 -- thread library</h1>
Worth: 15 points<br>
Assigned: Tuesday, September 26, 2017<br>
Due: Thursday, October 19, 2017

<h2 id="overview">1. Overview</h2>

<p>
This project will help you understand how threads and monitors are
implemented on uniprocessor and multiprocessor systems.  In this project,
you will implement a thread library similar to the one provided in
<a href="https://grader2.eecs.umich.edu/eecs482/project1/">Project 1</a>.

</p><h2 id="threadinterface">2. Interface to applications</h2>

<p>
This section describes the interface that your thread library and the
infrastructure provide to applications.  The interface consists of four
classes: <tt>cpu</tt>, <tt>thread</tt>, <tt>mutex</tt>, and <tt>cv</tt>,
which are declared in <a href="https://grader2.eecs.umich.edu/eecs482/project2/cpu.h"><tt>cpu.h</tt></a>,
<a href="https://grader2.eecs.umich.edu/eecs482/project2/thread.h"><tt>thread.h</tt></a>,
<a href="https://grader2.eecs.umich.edu/eecs482/project2/mutex.h"><tt>mutex.h</tt></a>, and <a href="https://grader2.eecs.umich.edu/eecs482/project2/cv.h"><tt>cv.h</tt></a> (do
not modify these files).  The interface is the same as the one provided <a href="https://grader2.eecs.umich.edu/eecs482/project1/">Project 1</a>, except for the two differences described
below.  Because of these differences, Project 1 and 2 use different versions
of <a href="https://grader2.eecs.umich.edu/eecs482/project2/cpu.h"><tt>cpu.h</tt></a> and
<a href="https://grader2.eecs.umich.edu/eecs482/project2/thread.h"><tt>thread.h</tt></a>.
<!--
<a href=libcpu.o><tt>libcpu.o</tt></a>
-->

</p><ul>

<li>
The <tt>cpu::boot</tt> function takes different parameters, which allow the
program to specify the number of CPUs and customize how interrupts are
generated.  One CPU will create the first thread,
which is initialized to call the function pointed to by
<tt>func</tt> with the argument <tt>arg</tt>.
<tt>async</tt>, <tt>sync</tt>, and <tt>random_seed</tt> control how timer
interrupts are generated.  As discussed in class, a timer interrupt
preempts the thread running on the current CPU and starts the next ready
thread.  If <tt>sync</tt> is true, timer interrupts will be triggered at
points in the program that are synchronized to executing instructions.  You
can generate different (but repeatable) patterns of synchronous timer
interrupt by changing <tt>random_seed</tt>.  If <tt>async</tt> is true, a
timer interrupt will be triggered on each CPU about once each millisecond.
A user program should
call <tt>cpu::boot</tt> exactly once (before calling any other thread
functions).  On success, <tt>cpu::boot</tt> does not return.

<pre>    static void boot(unsigned int num_cpus, thread_startfunc_t func, void *arg, bool async, bool sync, int random_seed);
</pre>

</li><li>
The <tt>thread</tt> class provides an extra function
<tt>thread::yield()</tt>, which allows a thread to voluntarily give up the
CPU to the next runnable thread (if there is one).

<pre>    static void yield();
</pre>

<p>
Note that <tt>thread::yield</tt> is a <tt>static</tt> member function and
is invoked on the <tt>thread</tt> class (not on an instance of the
<tt>thread</tt> class).

</p></li></ul>

<h2 id="threadlibrary">3. Thread library</h2>

You will write a thread library that implements the functions in
<a href="https://grader2.eecs.umich.edu/eecs482/project2/thread.h"><tt>thread.h</tt></a>,
<a href="https://grader2.eecs.umich.edu/eecs482/project2/mutex.h"><tt>mutex.h</tt></a>, and <a href="https://grader2.eecs.umich.edu/eecs482/project2/cv.h"><tt>cv.h</tt></a>.
You will also implement the <tt>cpu::init</tt> function, which is called by
the infrastructure when it starts a CPU.

<h3 id="init">3.1. Initializing and identifying a CPU</h3>

<p>
Your thread library will provide a function <tt>cpu::init</tt> (this
is the only member of the <tt>cpu</tt> class that you will implement).
When the user program calls <tt>cpu::boot</tt>, the infrastructure
activates <tt>num_cpus</tt> CPUs and causes each CPU to execute
<tt>cpu::init</tt>.
One of the CPUs will call <tt>cpu::init</tt> with the arguments
(<tt>func</tt> and <tt>arg</tt>) passed to <tt>cpu::boot</tt>; the
other CPUs will call <tt>cpu::init</tt> with <tt>nullptr</tt> argument values.

</p><p>
<tt>cpu::init</tt> should cause the CPU to run threads as they become
available.  <tt>cpu::init</tt> should not return to the caller, unless it
fails (in which case it should throw an appropriate exception, e.g.,
<tt>std::bad_alloc</tt> if it can't allocate memory).

</p><p>
If <tt>cpu::init</tt> is passed a function <tt>func</tt> that is not
<tt>nullptr</tt>, it should also create a thread that executes
<tt>func(arg)</tt>.

</p><p>
Your thread library may find it useful to identify which CPU a thread is
running on.  The function <tt>cpu::self</tt> returns a pointer to the
<tt>cpu</tt> object for the CPU this thread is running on.
Note that <tt>cpu::self</tt> is a <tt>static</tt> member function and is
invoked on the <tt>cpu</tt> class (not on an instance of the <tt>cpu</tt>
class).

</p><h3 id="createswap">3.2. Creating and swapping threads</h3>

<p>
You will be implementing your thread library on x86 PCs running the Linux
operating system.  Linux provides some library functions (<tt>getcontext</tt>,
<tt>makecontext</tt>, <tt>swapcontext</tt>) to help implement user-level
thread libraries.

</p><p>
Here's an example of how to use these functions to create a new thread
(read the Linux manual pages for details):

</p><hr>
<pre>#include &lt;ucontext.h&gt;

/*
 * Initialize a context structure by copying the current thread's context.
 */
getcontext(ucontext_ptr);           // ucontext_ptr has type (ucontext_t *)

/*
 * Direct the new thread to use a different stack.  Your thread library
 * should allocate STACK_SIZE bytes for each thread's stack.
 */
char *stack = new char [STACK_SIZE];
ucontext_ptr-&gt;uc_stack.ss_sp = stack;
ucontext_ptr-&gt;uc_stack.ss_size = STACK_SIZE;
ucontext_ptr-&gt;uc_stack.ss_flags = 0;
ucontext_ptr-&gt;uc_link = nullptr;

/*
 * Direct the new thread to start by calling start(arg1, arg2).
 */
makecontext(ucontext_ptr, (void (*)()) start, 2, arg1, arg2);
</pre>
<hr>

<p>
Use <tt>swapcontext</tt> to save the context of the current thread and switch to the
context of another thread.

</p><h3 id="createswap">3.3. Thread, mutex, and condition variable lifetimes</h3>

<p>
This section describes two subtle points related to lifetimes of objects.

</p><p>
First, note that a thread and the object representing that thread are
different concepts and have different lifetimes.  The thread is a stream of
execution; the thread object is a data structure that represents the
thread.

</p><p>
A <em>thread</em> finishes executing when it returns from the function that was
specified in the thread constructor.  Soon after the thread finishes executing,
the thread library should deallocate the memory used for the thread's stack
space and context.

</p><p>
A <em>thread object</em> is destroyed according to the normal rules of
object destruction.  E.g., if the thread object is a local variable of a
block, the thread object is destroyed when that block finishes.
<!--
The thread
object for the thread created by <tt>cpu::init</tt> should never be destroyed.
-->

</p><p>
The thread object may be destroyed <strong>before or after</strong> the
thread finishes executing, and the destruction of the thread object should
not affect the thread's execution (or vice versa).  If the thread object is
destroyed before the thread finishes executing, the thread should continue
executing.  If the thread finishes executing before the thread object is
destroyed, the memory used for the thread's stack and context should be
deallocated, but the thread object should not be destroyed (e.g., it could
still be used to <tt>join</tt> with the completed thread).

</p><p>
Second, think about when the constructor for a thread, mutex, or condition
variable may be called.  Threads are <em>not</em> allowed to be constructed
before the system is initialized (i.e., before <tt>cpu::boot</tt> has been
called).  However, mutexes and condition variables <em>are</em> allowed to
be constructed before <tt>cpu::boot</tt> is called (they are often global
variables, which are constructed before <tt>main</tt> is called; see
<a href="https://grader2.eecs.umich.edu/eecs482/project2/#example">Section 4</a> for an example).  This implies that the
constructors for mutexes and condition variables must not depend on any
cpu or thread library data.  In particular, they should not need to
manipulate interrupts.  You may assume that <tt>new</tt> is thread
safe.

</p><h3 id="interrupts">3.4. Interrupts</h3>

<p>
There are two types of interrupts: timer interrupts and inter-processor
interrupts (IPI).  Timer interrupts are generated periodically by the
infrastructure (if they are enabled by <tt>cpu::boot</tt>).
Inter-processor interrupts are received by one CPU when another CPU calls
<tt>cpu::interrupt_send</tt>.  Interrupts can only be received when
interrupts are enabled.  At the time <tt>cpu::init</tt> is called, interrupts
are disabled.

</p><p>
When a CPU receives an interrupt, the infrastructure consults the
<tt>cpu::interrupt_vector_table</tt> for that CPU and calls the interrupt
handler that is registered for that type of interrupt.  The interrupt
handler begins running with interrupts (still) enabled.

</p><p>
Your thread library is responsible for setting the entries in the interrupt
vector table.  <tt>cpu::interrupt_vector_table[TYPE]</tt> specifies the
address of the function to call when the specified CPU receives interrupt
<tt>TYPE</tt> (<tt>TYPE</tt> can be <tt>cpu::TIMER</tt> or
<tt>cpu::IPI</tt>).

</p><p>
Remember that interrupts should be disabled only when executing in your thread
library's code.  The code outside your thread library should never execute with
interrupts disabled.

</p><p>
To help ensure atomicity of multiple operations, your thread library will
manipulate interrupts using functions provided by the <tt>cpu</tt> class.
<tt>interrupt_send</tt> is a normal member function and sends an IPI to the
specified CPU.  <tt>interrupt_disable</tt>, <tt>interrupt_enable</tt>, and
<tt>interrupt_enable_suspend</tt> are <tt>static</tt> member functions;
they affect the CPU that called these functions and are invoked on the
<tt>cpu</tt> class (not on an instance of the <tt>cpu</tt> class).

</p><ul>

<li><tt>cpu::interrupt_disable</tt> disables interrupts on the executing CPU.

<pre>    static void interrupt_disable();
</pre>

</li><li><tt>cpu::interrupt_enable</tt> enables interrupts on the executing CPU.

<pre>    static void interrupt_enable();
</pre>

</li><li><tt>cpu::interrupt_enable_suspend</tt> atomically enables interrupts on the
executing CPU and suspends the executing CPU until it receives an
inter-processor interrupt (IPI) from another CPU.

<pre>    static void interrupt_enable_suspend();
</pre>

</li><li><tt>cpu::interrupt_send()</tt> sends an inter-processor interrupt to the
specified CPU.

<pre>    void interrupt_send();
</pre>

</li></ul>

<h3 id="guard">3.5. Guard variable</h3>

<p>
The infrastructure provides an atomic <tt>guard</tt> variable, which your thread
library must use to provide mutual exclusion on multiprocessors.
Remember that the switch invariant for multiprocessors specifies that this
guard variable must be <tt>true</tt> when calling <tt>swapcontext</tt>.
guard is initialized to <tt>false</tt>.

</p><p>
You may use any of the functions in
<a href="http://en.cppreference.com/w/cpp/atomic/atomic"><tt>std::atomic</tt></a>
to manipulate <tt>guard</tt> (e.g., <tt>store</tt>, <tt>exchange</tt>).
The <tt>std::atomic</tt> class doesn't provide a test-and-set function,
but you can easily achieve the same effect with other functions.

</p><p>
Hint: Beware of using the <tt>load</tt> function--it usually leads to a race
condition.

</p><h3 id="efficiency">3.6. Efficiency</h3>

<p>
Your thread library should manage the CPUs efficiently.  Minimize the
number of calls to <tt>swapcontext</tt>, and minimize busy waiting
(though some busy waiting in the thread library is inevitable when running
on a multiprocessor).  Suspend a CPU (using
<tt>cpu::interrupt_enable_suspend</tt>) when there are no runnable threads.

</p><p>
When all CPUs are suspended, the infrastructure will exit the process
with the message:

</p><pre>All CPUs suspended.  Exiting.
</pre>

<!--
Be careful when using static variables in your thread library.  Remember
that <tt>exit()</tt> will call the destructors for these variables, and
this may occur before other program variables (such as threads, mutexes,
and condition variables are destroyed.
-->

<h3 id="schedulingorder">3.7. Scheduling order</h3>

<p>
This section describes the specific scheduling order that your thread
library should follow.  Note that the thread library provided in
<a href="https://grader2.eecs.umich.edu/eecs482/project1/">Project 1</a> does not guarantee this scheduling
order, since that thread library was provided for developing concurrent
programs (which should work for any scheduling order).

</p><p>
All scheduling queues should be FIFO.  This includes the ready queue, the queue
of threads waiting for a mutex, the queue of threads waiting on a condition
variable, and the queue of threads waiting for a thread to exit.  All CPUs
should share a single ready queue.  Mutexes should be acquired by threads in
the order in which the mutex was requested (by <tt>mutex::lock</tt> or in
<tt>cv::wait</tt>).

</p><p>
When a thread creates a thread, unlocks a mutex, or signals/broadcasts a
condition variable, the caller does not yield its CPU.  The created or
unblocked thread should be put on the ready queue and executed when a CPU
becomes available.

</p><p>
When a thread wakes up in <tt>cv::wait</tt>, it is that thread's
responsibility to request the lock when it next runs.

</p><p>
<tt>cv::wait</tt> should not experience any spurious wakeups.

</p><h3 id="error">3.8. Error handling</h3>

<p>
Operating system code should be robust to bad user programs.  These fall
into four categories:

</p><ul>

<li> <strong>Questionable style.</strong>
A user program may not be written in the style we recommend for concurrent
programs, but it may still lie within the bounds of how a program is
allowed to use the thread library without causing an exception.  Here are a
few examples; none of these should be considered an error for Project 2.

    <ul>
    <li> Calling <tt>thread::yield</tt>.
    </li><li> Signaling without holding the lock (some may not even consider
	this poor style).
    </li><li> Deadlock.  Even trivial deadlocks are legal, such as a thread trying
        to acquire a mutex it has already locked, or a thread trying to
	<tt>join</tt> with itself.
    </li><li> Calling <tt>cv::wait</tt> without checking a condition in a
	<tt>while</tt> loop.
    </li><li> Calling <tt>cv::wait</tt> on one cv with different mutexes.
    </li><li> A thread that exits while holding a mutex (the mutex stays
        locked).
    </li></ul>
	
<!--
Ask on the forum if you're unsure whether you should consider a certain
behavior an error.
-->

</li><li> <strong>Misuse of thread functions</strong>
A user program may use a thread function in a manner that is explicitly
disallowed by Mesa monitors.  E.g., a thread may try to release a mutex it
hasn't locked.  Your thread library should detect such misuses and throw a
<tt>std::runtime_error</tt> exception.

</li><li> <strong>Resource exhaustion</strong>.  The process may exhaust a
resource needed by the OS.  In this project, the main resource used by
the OS is memory.  If the thread library is unable to service a request due
to lack of memory, it should throw a <tt>std::bad_alloc</tt> exception.
<!--
Applications can then catch the exception and proceed accordingly.
-->

</li><li> <strong>Undefined behavior</strong>
Some programming errors cause undefined behavior in C++, e.g.,
using uninitialized variables or pointers to free memory.  Examples
in this project include creating a thread with a bad function pointer
(e.g., <tt>nullptr</tt>) and destroying a thread object while it is still in
use by <tt>thread::join</tt>.  Your thread library may behave arbitrarily
for such errors.

</li></ul>

<p>
All programs with well-defined behavior (i.e., all but the last category in
the list above) can and should be used when testing your thread library,
and your thread library should produce well-defined results for them.

</p><p>
The other source of errors are bugs in the OS code itself (in this case,
your thread library).  While developing the OS, the best behavior in this
case is for the OS to detect the bug quickly and assert (this is called a
<em>panic</em> in kernel parlance).  These error checks are essential in
debugging concurrent programs, because they help flag error conditions
early.  <strong>Use assertion statements copiously in your thread library
to check for bugs in your code (for reference, 1/8 of the lines of code in
my thread library are assertions).</strong>

</p><p>
To make it easier for you to check for errors related to interrupts, the
infrastructure provides two functions, <tt>assert_interrupts_disabled</tt>
and <tt>assert_interrupts_enabled</tt> that your thread library can call to
check that the status of interrupts is as you expect.

<!--
<p>
We will not provide you with an exhaustive list of errors that you should
catch.  OS programmers must have a healthy (?) sense of paranoia to make their
system robust, so part of this assignment is thinking of and handling lots of
errors.  Unfortunately, there will be some errors that are not possible to
handle, because the thread library shares the address space with the user
program and can thus be corrupted by the user program.
-->

</p><p>
Hint: Autograder test cases 18-20 check how well your thread library
handles errors.

</p><h3 id="ucontext">3.9. Managing <tt>ucontext</tt> structs</h3>

<p>
Do not initialize a <tt>ucontext</tt> struct by copying another
<tt>ucontext</tt> struct.  Instead, initialize <tt>ucontext</tt> structs
through <tt>getcontext</tt>/<tt>makecontext</tt>, and manage them by
passing or storing pointers to <tt>ucontext</tt> structs, or by
passing/storing pointers to structs that contain a <tt>ucontext</tt> struct
(or by passing/storing pointers to structs that contain a pointer to a
<tt>ucontext</tt> struct, but this is overkill).  The pointers allow
the original <tt>ucontext</tt> struct to never be copied.

</p><p>
Why is it a bad idea to copy a <tt>ucontext</tt> struct?  The reason is
that you don't know what's in a <tt>ucontext</tt> struct.  Byte-for-byte
copying (e.g., using <tt>memcpy</tt>) can lead to errors unless you know
what's in the struct you're copying.  In particular, a <tt>ucontext</tt>
struct happens to contain a pointer to one of its data members.  If you
copy a <tt>ucontext</tt> using <tt>memcpy</tt>, you will copy the value of
this pointer, and the new copy will point to the <strong>old</strong>
copy's data member.  If you later deallocate the old copy (e.g., if it was
a local variable), then the new copy will point to garbage.  Copying
structs is also a bad idea for performance (the <tt>ucontext</tt> struct is
936 bytes on Linux/x86_64).

</p><p>
Unfortunately, it is rather easy to accidentally copy <tt>ucontext</tt> structs.
Some of the common ways are:
</p><li>passing a <tt>ucontext</tt> by value into a function
</li><li>copying the <tt>ucontext</tt> struct into an STL queue
</li><li>declaring a local <tt>ucontext</tt> variable is almost always a bad idea, since
it practically forces you to copy it

<p>
You should probably use the <tt>new</tt> operator to allocate
<tt>ucontext</tt> structs (or the struct containing a <tt>ucontext</tt>
struct).  If you use an STL class to allocate a <tt>ucontext</tt> struct,
make sure that STL class doesn't move its objects around in memory.  E.g.,
using vector to allocate <tt>ucontext</tt> structs is a bad idea, because
vectors will move memory around when they resize.

</p><h3 id="pimpl">3.10. Opaque pointers</h3>

<p>
You may not modify or rename the header files included in this handout.
However, you will probably need to add data and functions for the
classes declared in the headers (<tt>cpu</tt>, <tt>thread</tt>,
<tt>mutex</tt>, <tt>cv</tt>).  We use the <em>opaque pointer</em> idiom
(sometimes called <em>Pimpl</em>, for "pointer to implementation") to allow
you to add data/functions for a class without changing that class's header
file.

</p><p>
The <tt>cpu</tt>, <tt>thread</tt>, <tt>mutex</tt>, <tt>cv</tt> classes each
provide an <tt>impl_ptr</tt> member, which points to an instance of class
<tt>impl</tt>.  For example, class <tt>thread</tt> provides
<tt>thread::impl_ptr</tt>, which points to an instance of
class <tt>thread::impl</tt>.

</p><p>
You may define each <tt>impl</tt> class and use each <tt>impl_ptr</tt>
however you like.  For example, you can store custom data and
functions you need for a <tt>mutex</tt> in an instance of
the <tt>mutex::impl</tt> class, then point to this instance via
a mutex's <tt>impl_ptr</tt>.

</p><p>
Typically, a class constructor will allocate the <tt>impl</tt> object and
initialize the <tt>impl_ptr</tt> to point to the allocated data.
For the <tt>cpu</tt> class, do these tasks in <tt>cpu::init</tt>,
since you're not writing the <tt>cpu</tt> class constructor.

</p><h2 id="example">4. Example application</h2>

<p>
Here is a short program that uses the above thread library, along with the
output generated by the program.  Make sure you understand how the CPU is
switching between two threads while they're executing the <tt>loop</tt>
function.  <tt>i</tt> is on the stack and so is private to each thread.
<tt>g</tt> is a global variable and so is shared among the two threads.

</p><hr>
<pre>#include &lt;iostream&gt;
#include &lt;cstdlib&gt;
#include "thread.h"

using namespace std;

int g = 0;

mutex mutex1;
cv cv1;

void loop(void *a)
{
    char *id = (char *) a;
    int i;

    mutex1.lock();
    cout &lt;&lt; "loop called with id " &lt;&lt; id &lt;&lt; endl;

    for (i=0; i&lt;5; i++, g++) {
	cout &lt;&lt; id &lt;&lt; ":\t" &lt;&lt; i &lt;&lt; "\t" &lt;&lt; g &lt;&lt; endl;
        mutex1.unlock();
	thread::yield();
        mutex1.lock();
    }
    cout &lt;&lt; id &lt;&lt; ":\t" &lt;&lt; i &lt;&lt; "\t" &lt;&lt; g &lt;&lt; endl;
    mutex1.unlock();
}

void parent(void *a)
{
    intptr_t arg = (intptr_t) a;

    mutex1.lock();
    cout &lt;&lt; "parent called with arg " &lt;&lt; arg &lt;&lt; endl;
    mutex1.unlock();

    thread t1 ( (thread_startfunc_t) loop, (void *) "child thread");

    loop( (void *) "parent thread");
}

int main()
{
    cpu::boot(1, (thread_startfunc_t) parent, (void *) 100, false, false, 0);
}

<hr>
parent called with arg 100
loop called with id parent thread
parent thread:	0	0
loop called with id child thread
child thread:	0	0
parent thread:	1	1
child thread:	1	2
parent thread:	2	3
child thread:	2	4
parent thread:	3	5
child thread:	3	6
parent thread:	4	7
child thread:	4	8
parent thread:	5	9
child thread:	5	10
All CPUs suspended.  Exiting.
</pre>
<hr>

<h2 id="tips">5. Tips</h2>

<p>
Start by implementing <tt>cpu::init</tt>, <tt>thread::thread</tt>, and
<tt>thread::yield</tt>.  Don't worry at first about atomicity in the thread
library or supporting multiple processors (but remember that interrupts
should be enabled whenever user code is running).
After you get that system working, implement the other thread functions.
Next, add calls to <tt>cpu::interrupt_disable</tt> and
<tt>cpu::interrupt_enable</tt> to ensure your library works in the presence of
interrupts.  You'll need to think about what should happen when an
interrupt occurs and how to guarantee atomicity in your thread library
when they occur.  Finally, add support for multiple processors.  Use
the guard variable to ensure atomicity for multiprocessors, and think
about what a CPU should do when there are no runnable threads.

</p><h2 id="testcases">6. Test cases</h2>

<p>
An integral (and graded) part of writing your thread library will be to write a
suite of test cases to validate any thread library.  This is common practice in
the real world--software companies maintain a suite of test cases for their
programs and use this suite to check the program's correctness after a change.
Writing a comprehensive suite of test cases will deepen your understanding of
how to use and implement threads, and it will help you a lot as you debug your
thread library.

</p><p>
Each test case for the thread library will be a short C++ program that uses
functions in the thread library (e.g., the example program in
<a href="https://grader2.eecs.umich.edu/eecs482/project2/#example">Section 4</a>).  The name of each test case should
start with <tt>test</tt> and end with <tt>.cc</tt> or <tt>.cpp</tt>, e.g.,
<tt>test1.cc</tt>.

</p><p>
Each test case should be run without any arguments and should not use any
input files.  Test cases should exit(0) when run with a correct thread
library (normally this will happen when your test case's last runnable
thread ends or blocks).  If you submit your disk scheduler as a test case,
remember to adapt its call to <tt>cpu::boot</tt> and to
specify all inputs (number of requesters, buffers, and the list
of requests) statically in the program.  The list of requests should be
short to make a good test case (i.e., one that you can trace through what
should happen).

</p><p>
The test cases you submit should call <tt>cpu::boot</tt> with
<tt>num_cpus=1</tt> and without enabling asynchronous or synchronous timer
interrupts.  All the instructor's buggy thread libraries can be exposed
with a single CPU and without timer interrupts.

</p><p>
While you cannot submit test cases that use multiple CPUs or enable timer
interrupts, you <strong>should</strong> write and run such test cases
yourself.

</p><p>
Your test suite may contain up to 22 test cases.  Each test case must
generate less than 10 KB of output, use less than 100 MB of memory, and
take less than 60 seconds to run.  These limits are much larger than needed
for full credit.  You will submit your suite of test cases together with
your thread library, and we will grade your test suite according to how
thoroughly it exercises a thread library.  <a href="https://grader2.eecs.umich.edu/eecs482/project2/#grading">Section 9</a>
describes how your test suite will be graded.

</p><h2 id="logistics">7. Project logistics</h2>

<p>
Write your thread library in C++ on Linux.  The internal functions and
global variables in your thread library should be declared <tt>static</tt>
to prevent naming conflicts with programs that link with your thread
library.

</p><p>
Use <tt>g++ 4.8.5</tt> to compile your programs.

<!--
To use <tt>g++ 4.8.3</tt>
on CAEN computers, put the following command in your startup file (e.g.,
<tt>~/.profile</tt>):

<pre>
module load gcc
module load gdb/7.5.1
</pre>
-->

<!--
<p>
You should also set the <tt>LD_BIND_NOW</tt> environment variable to 1.
This works around an apparent incompatibility between the thread library
and the Linux dynamic linker.  Add the following line to your 
<tt>~/.profile</tt>:

<pre>
export LD_BIND_NOW=1
</pre>
-->

</p><p>
You may use any functions included in the standard C++ library, except
the C++11 thread facilities.  You should not use any libraries other than
the standard C++ library.  To compile an application program (e.g.,
<tt>app.cc</tt>) with your thread library (e.g., <tt>thread.cc</tt>), run:

</p><pre>g++ -g -Wall thread.cc app.cc libcpu.o -ldl -pthread -std=c++11
</pre>

<p>
When running <tt>gdb</tt>, you will probably find it useful to direct
<tt>gdb</tt> to ignore <tt>SIGUSR1</tt> events (used by the project
infrastructure).  To do this, use the following command in <tt>gdb</tt>:
</p><pre>handle SIGUSR1 nostop noprint
</pre>

<p>
The infrastructure simulates multiple CPUs as multiple POSIX threads.
You can view and switch among these simulated CPUs via the following commands:
</p><pre>info threads
thread &lt;N&gt;          (Note: &lt;N&gt; is the ID of the thread you want to view in gdb.  Thread ID 1 is used by the infrastructure.)
</pre>

<p>
Debugging print statements in the thread library should use
<tt>printf</tt>, not <tt>cout</tt>.  This avoids deadlocking with user code
(which should use <tt>cout</tt>).

</p><p>
Your thread library code may be in multiple files.
Each file name must end with <tt>.cc</tt>, <tt>.cpp</tt>, or <tt>.h</tt>
and must not start with <tt>test</tt>.

</p><p>
We have created a private <a href="https://github.com/eecs482">github</a>
repository for your group
(<tt>eecs482/&lt;group&gt;.2</tt>), where <tt>&lt;group&gt;</tt> is
the sorted, dot-separated list of your group members' uniqnames.  Initialize
your local repository by cloning the (empty) repository from github, e.g.,

</p><pre>git clone git@github.com:eecs482/uniqnameA.uniqnameB.2
</pre>

<h2 id="grading">8. Grading, auto-grading, and formatting</h2>

<p>
To help you validate your programs, your submissions will be graded
automatically, and the results will be provided to you.  You may then
continue to work on the project and re-submit.  The results from the
auto-grader will not be very illuminating; they won't tell you where your
problem is or give you the test programs.  The main purpose of the
auto-grader is to help you know to keep working on your project (rather
than thinking it's perfect and ending up with a 0).  The best way to debug
your program is to generate your own test cases, figure out the correct
answers, and compare your program's output to the correct answers.  This is
also one of the best ways to learn the concepts in the project.

</p><p>
The student suite of test cases will be graded according to how thoroughly
they test a thread library.  We will judge thoroughness of the test suite
by how well it exposes potential bugs in a thread library.  The auto-grader
will first compile a test case with a correct thread library and generate
the correct output (on <tt>stdout</tt>, i.e., the stream used by
<tt>cout</tt>) for this test case.  Test cases should not cause any compile
or run-time errors when compiled with a correct thread library.  The
auto-grader will then compile the test case with a set of buggy thread
libraries.  A test case exposes a buggy thread library by causing it to
generate output (on <tt>stdout</tt>) that differs from the correct output.
The test suite is graded based on how many of the buggy thread libraries
were exposed by at least one test case.  This is known as <em>mutation
testing</em> in the research literature on automated testing.

</p><p>
You may submit your program as many times as you like.  However, only the
feedback from the first submission of each day will be provided to you
Later submissions on that day will be graded and cataloged, but the results
will not be provided to you.  See the <a href="https://grader2.eecs.umich.edu/eecs482/faq.html#limit">FAQ</a> for
why we use this policy.

</p><p>
In addition to this one-per-day policy, you will be given 3 bonus submissions
that also provide feedback.  These will be used automatically--any submission
you make after the first one of that day will use one of your bonus
submissions.  After your 3 bonus submissions are used up, the system will
continue to provide 1 feedback per day.

</p><p>
Because you are writing concurrent programs, the auto-grader may return
non-deterministic results.  In particular, test cases 28-41 are
non-deterministic.

</p><p>
Because your programs will be auto-graded, you must be careful to follow the
exact rules in the project description.  In particular:

</p><ul>

<li>Your thread library should not generate any output.  Only the program
using your thread library should generate output.

</li><li>Do not modify or rename the header files included in this handout.

</li></ul>

<p>
In addition to the auto-grader's evaluation of your program's correctness, a
human grader will evaluate your program on issues such as the clarity and
completeness of your documentation, coding style, the efficiency, brevity, and
understandability of your code, etc..  Your final score will be the product of
the hand-graded score (between 1-1.12) and the auto-grader score.

</p><h2 id="submission">9. Turning in the project</h2>

<p>
<a href="https://grader2.eecs.umich.edu/eecs482/submit.php?2">Submit</a> the following files for your thread library:

</p><ul>
<li>C++ files for your thread library.  File names should end in
<tt>.cc</tt>, <tt>.cpp</tt>, or <tt>.h</tt> and must not start with
<tt>test</tt>.  Do not submit the files provided in this handout.

</li><li>Suite of test cases.  Each test case should be in a single file.  File
names should start with <tt>test</tt> and end with <tt>.cc</tt> or
<tt>.cpp</tt>.

</li></ul>

<p>
Each person should also describe the contributions of each team member
using the following <a href="https://grader2.eecs.umich.edu/eecs482/peer.php?peer2">web form</a>.

</p><p>
The official time of submission for your project will be the time of your
last submission.  Submissions after the due date will automatically use up
your late days; if you have no late days left, late submissions will not be
counted.

</p><h2 id="files">10. Files included in this handout (<a href="https://grader2.eecs.umich.edu/eecs482/project2/handout.zip">zip file</a>)
</h2>

<ul>
<li><a href="https://grader2.eecs.umich.edu/eecs482/project2/cpu.h"><tt>cpu.h</tt></a>
</li><li><a href="https://grader2.eecs.umich.edu/eecs482/project2/cv.h"><tt>cv.h</tt></a>
</li><li><a href="https://grader2.eecs.umich.edu/eecs482/project2/libcpu.o"><tt>libcpu.o</tt></a>
</li><li><a href="https://grader2.eecs.umich.edu/eecs482/project2/mutex.h"><tt>mutex.h</tt></a>
</li><li><a href="https://grader2.eecs.umich.edu/eecs482/project2/thread.h"><tt>thread.h</tt></a>
</li></ul>

<p>
<strong>Experimental</strong>: If you are running Ubuntu Linux, you may be
able to use this (unofficial and unsupported) version of
<a href="https://grader2.eecs.umich.edu/eecs482/project2/libcpu.ubuntu.o"><tt>libcpu.o</tt></a>.



</p></li></body></html>